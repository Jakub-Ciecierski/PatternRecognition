#-----------------------------------------------------------------------#
#------------------------------ GENERAL --------------------------------#
#-----------------------------------------------------------------------#

TestType Enum break lines in the type string

#-----------------------------------------------------------------------#
#------------------------------ PAPER 2 --------------------------------#
#-----------------------------------------------------------------------#
Cluster Evaluation methods: PBM, McClain-Rao i Ratkowsky-Lance.

TODAY:

Normalization
Save native training and testing split
Load native from that saved files

ALL:

1. klasy cyfr native dzielimy na dwa równoliczne zbiory: treningowy i testowy,

2. wybieramy kilka klas, pewnie trzeba będzie przeprowadzić obliczenia dla
zestawów klas a) 0, 1, 2, b) 4, 5, 6, c) 6, 8, 9, d) dla wszystkich
dziesięciu klas; ale na początek tylko dla jednego zestawu a),

3. dla wybranego zestawu dzielimy zbiór treningowy na 2, 3, 4, ...., c grup
za pomocą k-means, zbiór treningowy traktujemy jako całość zapominając, że składa się z kilku klas,

5. określamy jakość grupowania za pomocą prediction strength,
trzeba będzie zastosować jeszcze jedną dwie inne miary,
później wskażę jakie, ewentualnie proszę się samemu rozejrzeć,

6. otaczamy znalezione grupy równoległobokami i elipsoidami,

7. sprawdzamy miary jakości na zbiorze testowym,
tzn. ile elementów testowych wypada poza
obszar i jak wygląda odrzucanie elementów foreign.

Trzeba jeszcze sprawdzić wyniki dla oryginalnych wartości cech i dla
wartości znormalizowanych do przedziału [0,1].
Normalizacja według wzoru: x_norm = (x-min)/(max-min)

To jest mniej więcej powtórzenie dotychczasowych obliczeń z tą różnicą,
że inaczej dzielimy zbiór treningowy native.
Ten inny podział zbioru treningowego będzie podstawą do dalszych prac, ale o tym później.
